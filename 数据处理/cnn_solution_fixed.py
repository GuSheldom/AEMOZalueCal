import numpy as np

def solve_cnn_question():
    """è§£ç­”CNNç›¸å…³é—®é¢˜"""
    print("=" * 80)
    print("Question 3: Baby Convolutional Neural Network è§£ç­”")
    print("=" * 80)
    
    print("\né¢˜ç›®è®¾å®šï¼š")
    print("- 3Ã—3å›¾åƒï¼Œç‰¹å¾ä¸º x = (xâ‚, xâ‚‚, ..., xâ‚‰)")
    print("- CNNåº”ç”¨æ»¤æ³¢å™¨åˆ°æ¯ä¸ª2Ã—2å­ç½‘æ ¼")
    print("- å››ä¸ª2Ã—2å­ç½‘æ ¼ï¼Œæ¯ä¸ªäº§ç”Ÿä¸€ä¸ªå€¼ uâ‚, uâ‚‚, uâ‚ƒ, uâ‚„")
    print("- é€»è¾‘å‡½æ•°ï¼šh = 1/(1 + e^(-(wâ‚uâ‚ + wâ‚‚uâ‚‚ + wâ‚ƒuâ‚ƒ + wâ‚„uâ‚„)))")
    
    # æ˜¾ç¤ºæ»¤æ³¢å™¨å‚æ•°å’Œæƒé‡
    print("\nå‚æ•°ï¼š")
    print("- æ»¤æ³¢å™¨å‚æ•°ï¼šÎ¸ = (Î¸â‚, Î¸â‚‚, Î¸â‚ƒ, Î¸â‚„)")
    print("- æƒé‡å‚æ•°ï¼šw = (wâ‚, wâ‚‚, wâ‚ƒ, wâ‚„)")
    
    # æ˜¾ç¤ºuå€¼çš„è®¡ç®—
    print("\nuå€¼è®¡ç®—ï¼š")
    print("uâ‚ = Î¸â‚xâ‚ + Î¸â‚‚xâ‚‚ + Î¸â‚ƒxâ‚„ + Î¸â‚„xâ‚…")
    print("uâ‚‚ = Î¸â‚xâ‚‚ + Î¸â‚‚xâ‚ƒ + Î¸â‚ƒxâ‚… + Î¸â‚„xâ‚†")
    print("uâ‚ƒ = Î¸â‚xâ‚„ + Î¸â‚‚xâ‚… + Î¸â‚ƒxâ‚‡ + Î¸â‚„xâ‚ˆ")
    print("uâ‚„ = Î¸â‚xâ‚… + Î¸â‚‚xâ‚† + Î¸â‚ƒxâ‚ˆ + Î¸â‚„xâ‚‰")

def part_a_gradients():
    """(a) è®¡ç®—æ¢¯åº¦ âˆ‚h/âˆ‚Î¸â±¼ å’Œ âˆ‚h/âˆ‚wâ±¼"""
    print("\n" + "="*60)
    print("(a) è®¡ç®—æ¢¯åº¦ âˆ‚h/âˆ‚Î¸â±¼ å’Œ âˆ‚h/âˆ‚wâ±¼ [6 marks]")
    print("="*60)
    
    print("\nè®¾ z = wâ‚uâ‚ + wâ‚‚uâ‚‚ + wâ‚ƒuâ‚ƒ + wâ‚„uâ‚„")
    print("åˆ™ h = 1/(1 + e^(-z)) = Ïƒ(z) (sigmoidå‡½æ•°)")
    
    print("\næ­¥éª¤1: ä½¿ç”¨é“¾å¼æ³•åˆ™")
    print("âˆ‚h/âˆ‚Î¸â±¼ = (âˆ‚h/âˆ‚z) Ã— (âˆ‚z/âˆ‚Î¸â±¼)")
    print("âˆ‚h/âˆ‚wâ±¼ = (âˆ‚h/âˆ‚z) Ã— (âˆ‚z/âˆ‚wâ±¼)")
    
    print("\næ­¥éª¤2: è®¡ç®— âˆ‚h/âˆ‚z")
    print("âˆ‚h/âˆ‚z = âˆ‚/âˆ‚z [1/(1 + e^(-z))]")
    print("      = e^(-z)/(1 + e^(-z))Â²")
    print("      = [1/(1 + e^(-z))] Ã— [e^(-z)/(1 + e^(-z))]")
    print("      = h Ã— (1 - h)")
    
    print("\næ­¥éª¤3: è®¡ç®— âˆ‚z/âˆ‚Î¸â±¼")
    print("ç”±äº z = wâ‚uâ‚ + wâ‚‚uâ‚‚ + wâ‚ƒuâ‚ƒ + wâ‚„uâ‚„")
    print("âˆ‚z/âˆ‚Î¸â±¼ = wâ‚(âˆ‚uâ‚/âˆ‚Î¸â±¼) + wâ‚‚(âˆ‚uâ‚‚/âˆ‚Î¸â±¼) + wâ‚ƒ(âˆ‚uâ‚ƒ/âˆ‚Î¸â±¼) + wâ‚„(âˆ‚uâ‚„/âˆ‚Î¸â±¼)")
    
    print("\nè®¡ç®—å„ä¸ª âˆ‚uáµ¢/âˆ‚Î¸â±¼ï¼š")
    print("âˆ‚uâ‚/âˆ‚Î¸â‚ = xâ‚,  âˆ‚uâ‚/âˆ‚Î¸â‚‚ = xâ‚‚,  âˆ‚uâ‚/âˆ‚Î¸â‚ƒ = xâ‚„,  âˆ‚uâ‚/âˆ‚Î¸â‚„ = xâ‚…")
    print("âˆ‚uâ‚‚/âˆ‚Î¸â‚ = xâ‚‚,  âˆ‚uâ‚‚/âˆ‚Î¸â‚‚ = xâ‚ƒ,  âˆ‚uâ‚‚/âˆ‚Î¸â‚ƒ = xâ‚…,  âˆ‚uâ‚‚/âˆ‚Î¸â‚„ = xâ‚†")
    print("âˆ‚uâ‚ƒ/âˆ‚Î¸â‚ = xâ‚„,  âˆ‚uâ‚ƒ/âˆ‚Î¸â‚‚ = xâ‚…,  âˆ‚uâ‚ƒ/âˆ‚Î¸â‚ƒ = xâ‚‡,  âˆ‚uâ‚ƒ/âˆ‚Î¸â‚„ = xâ‚ˆ")
    print("âˆ‚uâ‚„/âˆ‚Î¸â‚ = xâ‚…,  âˆ‚uâ‚„/âˆ‚Î¸â‚‚ = xâ‚†,  âˆ‚uâ‚„/âˆ‚Î¸â‚ƒ = xâ‚ˆ,  âˆ‚uâ‚„/âˆ‚Î¸â‚„ = xâ‚‰")
    
    print("\nå› æ­¤ï¼š")
    print("âˆ‚z/âˆ‚Î¸â‚ = wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚„ + wâ‚„xâ‚…")
    print("âˆ‚z/âˆ‚Î¸â‚‚ = wâ‚xâ‚‚ + wâ‚‚xâ‚ƒ + wâ‚ƒxâ‚… + wâ‚„xâ‚†")
    print("âˆ‚z/âˆ‚Î¸â‚ƒ = wâ‚xâ‚„ + wâ‚‚xâ‚… + wâ‚ƒxâ‚‡ + wâ‚„xâ‚ˆ")
    print("âˆ‚z/âˆ‚Î¸â‚„ = wâ‚xâ‚… + wâ‚‚xâ‚† + wâ‚ƒxâ‚ˆ + wâ‚„xâ‚‰")
    
    print("\næ­¥éª¤4: è®¡ç®— âˆ‚z/âˆ‚wâ±¼")
    print("âˆ‚z/âˆ‚wâ‚ = uâ‚")
    print("âˆ‚z/âˆ‚wâ‚‚ = uâ‚‚")
    print("âˆ‚z/âˆ‚wâ‚ƒ = uâ‚ƒ")
    print("âˆ‚z/âˆ‚wâ‚„ = uâ‚„")
    
    print("\næœ€ç»ˆç»“æœï¼š")
    print("âˆ‚h/âˆ‚Î¸â‚ = h(1-h) Ã— (wâ‚xâ‚ + wâ‚‚xâ‚‚ + wâ‚ƒxâ‚„ + wâ‚„xâ‚…)")
    print("âˆ‚h/âˆ‚Î¸â‚‚ = h(1-h) Ã— (wâ‚xâ‚‚ + wâ‚‚xâ‚ƒ + wâ‚ƒxâ‚… + wâ‚„xâ‚†)")
    print("âˆ‚h/âˆ‚Î¸â‚ƒ = h(1-h) Ã— (wâ‚xâ‚„ + wâ‚‚xâ‚… + wâ‚ƒxâ‚‡ + wâ‚„xâ‚ˆ)")
    print("âˆ‚h/âˆ‚Î¸â‚„ = h(1-h) Ã— (wâ‚xâ‚… + wâ‚‚xâ‚† + wâ‚ƒxâ‚ˆ + wâ‚„xâ‚‰)")
    print()
    print("âˆ‚h/âˆ‚wâ‚ = h(1-h) Ã— uâ‚")
    print("âˆ‚h/âˆ‚wâ‚‚ = h(1-h) Ã— uâ‚‚")
    print("âˆ‚h/âˆ‚wâ‚ƒ = h(1-h) Ã— uâ‚ƒ")
    print("âˆ‚h/âˆ‚wâ‚„ = h(1-h) Ã— uâ‚„")

def part_b_likelihood():
    """(b) æ¨å¯¼è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°"""
    print("\n" + "="*60)
    print("(b) æ¨å¯¼è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•° [3 marks]")
    print("="*60)
    
    print("\nç»™å®šï¼š")
    print("- è®­ç»ƒæ•°æ®é›†ï¼š{(xáµ¢, yáµ¢)}áµ¢â‚Œâ‚á´º")
    print("- xáµ¢ âˆˆ â„â¹ï¼Œyáµ¢ âˆˆ {0,1}")
    print("- xáµ¢â±¼ è¡¨ç¤ºç¬¬iä¸ªæ•°æ®ç‚¹çš„ç¬¬jä¸ªç‰¹å¾")
    
    print("\næ­¥éª¤1: å•ä¸ªæ•°æ®ç‚¹çš„ä¼¼ç„¶")
    print("å¯¹äºäºŒå…ƒåˆ†ç±»ï¼Œæ¯ä¸ªæ•°æ®ç‚¹çš„ä¼¼ç„¶ä¸ºï¼š")
    print("P(yáµ¢|xáµ¢) = háµ¢Ê¸â± Ã— (1-háµ¢)Â¹â»Ê¸â±")
    print("å…¶ä¸­ háµ¢ = h(xáµ¢, Î¸, w)")
    
    print("\nè¿™ä¸ªå…¬å¼çš„å«ä¹‰ï¼š")
    print("- å½“ yáµ¢ = 1 æ—¶ï¼šP(yáµ¢|xáµ¢) = háµ¢")
    print("- å½“ yáµ¢ = 0 æ—¶ï¼šP(yáµ¢|xáµ¢) = 1-háµ¢")
    
    print("\næ­¥éª¤2: æ€»ä¼¼ç„¶å‡½æ•°")
    print("å‡è®¾æ•°æ®ç‚¹ç‹¬ç«‹ï¼Œæ€»ä¼¼ç„¶ä¸ºï¼š")
    print("L(Î¸, w) = âˆáµ¢â‚Œâ‚á´º P(yáµ¢|xáµ¢)")
    print("        = âˆáµ¢â‚Œâ‚á´º háµ¢Ê¸â± Ã— (1-háµ¢)Â¹â»Ê¸â±")
    
    print("\næ­¥éª¤3: å¯¹æ•°ä¼¼ç„¶å‡½æ•°")
    print("å–å¯¹æ•°ç®€åŒ–ä¹˜ç§¯ï¼š")
    print("â„“(Î¸, w) = log L(Î¸, w)")
    print("         = âˆ‘áµ¢â‚Œâ‚á´º [yáµ¢ log háµ¢ + (1-yáµ¢) log(1-háµ¢)]")
    
    print("\næ­¥éª¤4: è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°")
    print("æœºå™¨å­¦ä¹ ä¸­é€šå¸¸æœ€å°åŒ–æŸå¤±ï¼Œæ‰€ä»¥å–è´Ÿå·ï¼š")
    print()
    print("NLL(Î¸, w) = -â„“(Î¸, w)")
    print("          = -âˆ‘áµ¢â‚Œâ‚á´º [yáµ¢ log háµ¢ + (1-yáµ¢) log(1-háµ¢)]")
    print("          = âˆ‘áµ¢â‚Œâ‚á´º [-yáµ¢ log háµ¢ - (1-yáµ¢) log(1-háµ¢)]")
    
    print("\nè¿™å°±æ˜¯è‘—åçš„äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼")

def part_c_sgd_algorithm():
    """(c) æè¿°SGDç®—æ³•"""
    print("\n" + "="*60)
    print("(c) SGDç®—æ³•ä¸mini-batchæ–¹æ³• [8 marks]")
    print("="*60)
    
    print("\néšæœºæ¢¯åº¦ä¸‹é™(SGD)ç®—æ³•ï¼š")
    print("-" * 40)
    
    print("\n1. åˆå§‹åŒ–ï¼š")
    print("   - éšæœºåˆå§‹åŒ–å‚æ•° Î¸â½â°â¾ å’Œ wâ½â°â¾ (é€šå¸¸ç”¨å°éšæœºæ•°)")
    print("   - è®¾ç½®å­¦ä¹ ç‡ Î± > 0 (å¦‚ 0.01, 0.001)")
    print("   - è®¾ç½®mini-batchå¤§å° B (å¦‚ 32, 64, 128)")
    print("   - è®¾ç½®æœ€å¤§epochæ•° T")
    
    print("\n2. å¯¹äºæ¯ä¸ªepoch t = 1, 2, ..., Tï¼š")
    
    print("\n   a) æ•°æ®é¢„å¤„ç†ï¼š")
    print("      - éšæœºæ‰“ä¹±è®­ç»ƒæ•°æ® (shuffle)")
    print("      - å°†Nä¸ªæ•°æ®ç‚¹åˆ†æˆ âŒˆN/BâŒ‰ ä¸ªmini-batches")
    
    print("\n   b) å¯¹äºæ¯ä¸ªmini-batch â„¬ = {(xáµ¢, yáµ¢)}áµ¢âˆˆâ„¬ï¼š")
    
    print("\n      i) å‰å‘ä¼ æ’­ (Forward Pass)ï¼š")
    print("         å¯¹batchä¸­æ¯ä¸ªæ ·æœ¬(xáµ¢, yáµ¢)ï¼š")
    print("         â€¢ è®¡ç®— uâ‚áµ¢, uâ‚‚áµ¢, uâ‚ƒáµ¢, uâ‚„áµ¢ (åº”ç”¨æ»¤æ³¢å™¨)")
    print("         â€¢ è®¡ç®— záµ¢ = wâ‚uâ‚áµ¢ + wâ‚‚uâ‚‚áµ¢ + wâ‚ƒuâ‚ƒáµ¢ + wâ‚„uâ‚„áµ¢")
    print("         â€¢ è®¡ç®— háµ¢ = 1/(1 + e^(-záµ¢))")
    
    print("\n      ii) è®¡ç®—mini-batchæŸå¤±ï¼š")
    print("          L_batch = (1/B) Ã— âˆ‘áµ¢âˆˆâ„¬ [-yáµ¢ log háµ¢ - (1-yáµ¢) log(1-háµ¢)]")
    
    print("\n      iii) åå‘ä¼ æ’­ (Backward Pass) - è®¡ç®—æ¢¯åº¦ï¼š")
    print("           å¯¹äºæ¯ä¸ªå‚æ•°Î¸â±¼ï¼š")
    print("           âˆ‚L_batch/âˆ‚Î¸â±¼ = (1/B) Ã— âˆ‘áµ¢âˆˆâ„¬ âˆ‚[-yáµ¢ log háµ¢ - (1-yáµ¢) log(1-háµ¢)]/âˆ‚Î¸â±¼")
    print()
    print("           ä½¿ç”¨é“¾å¼æ³•åˆ™ï¼š")
    print("           âˆ‚L_batch/âˆ‚Î¸â±¼ = (1/B) Ã— âˆ‘áµ¢âˆˆâ„¬ (háµ¢ - yáµ¢) Ã— (âˆ‚háµ¢/âˆ‚Î¸â±¼)")
    print("           å…¶ä¸­ï¼šâˆ‚háµ¢/âˆ‚Î¸â±¼ = háµ¢(1-háµ¢) Ã— (âˆ‚záµ¢/âˆ‚Î¸â±¼)")
    print()
    print("           ç±»ä¼¼åœ°ï¼š")
    print("           âˆ‚L_batch/âˆ‚wâ±¼ = (1/B) Ã— âˆ‘áµ¢âˆˆâ„¬ (háµ¢ - yáµ¢) Ã— háµ¢(1-háµ¢) Ã— uâ±¼áµ¢")
    
    print("\n      iv) å‚æ•°æ›´æ–° (Parameter Update)ï¼š")
    print("          Î¸â±¼ â† Î¸â±¼ - Î± Ã— (âˆ‚L_batch/âˆ‚Î¸â±¼)")
    print("          wâ±¼ â† wâ±¼ - Î± Ã— (âˆ‚L_batch/âˆ‚wâ±¼)")
    
    print("\n3. å¯é€‰ï¼šæ¯ä¸ªepochååœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ€§èƒ½")
    print("4. é‡å¤ç›´åˆ°æ”¶æ•›æˆ–è¾¾åˆ°æœ€å¤§epochæ•°")
    
    print("\nå…³é”®è¦ç‚¹ï¼š")
    print("â€¢ Mini-batchæ¢¯åº¦æ˜¯çœŸå®æ¢¯åº¦çš„æ— åä¼°è®¡")
    print("â€¢ Batch size B å½±å“ï¼š")
    print("  - å°Bï¼šæ›´éšæœºï¼Œå¯èƒ½æ›´å¥½åœ°é€ƒç¦»å±€éƒ¨æœ€ä¼˜")
    print("  - å¤§Bï¼šæ›´ç¨³å®šï¼Œä½†å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜")
    print("â€¢ å­¦ä¹ ç‡ Î± éœ€è¦è°ƒä¼˜ï¼š")
    print("  - å¤ªå¤§ï¼šå¯èƒ½ä¸æ”¶æ•›æˆ–éœ‡è¡")
    print("  - å¤ªå°ï¼šæ”¶æ•›å¤ªæ…¢")
    print("â€¢ é€šå¸¸ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ç­–ç•¥")

def create_latex_solution():
    """åˆ›å»ºLaTeXè§£ç­”"""
    print("\n" + "="*60)
    print("åˆ›å»ºLaTeXæ ¼å¼è§£ç­”...")
    print("="*60)
    
    latex_content = r"""
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{algorithm}
\usepackage{algorithmic}

\geometry{a4paper, margin=1in}

\title{Question 3: Baby Convolutional Neural Network Solution}
\author{}
\date{}

\begin{document}

\maketitle

\section*{(a) Compute gradients $\frac{\partial h}{\partial \theta_j}$ and $\frac{\partial h}{\partial w_j}$ [6 marks]}

Given:
\begin{align}
u_1 &= \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_4 + \theta_4 x_5 \\
u_2 &= \theta_1 x_2 + \theta_2 x_3 + \theta_3 x_5 + \theta_4 x_6 \\
u_3 &= \theta_1 x_4 + \theta_2 x_5 + \theta_3 x_7 + \theta_4 x_8 \\
u_4 &= \theta_1 x_5 + \theta_2 x_6 + \theta_3 x_8 + \theta_4 x_9 \\
h &= \frac{1}{1 + e^{-(w_1 u_1 + w_2 u_2 + w_3 u_3 + w_4 u_4)}}
\end{align}

Let $z = w_1 u_1 + w_2 u_2 + w_3 u_3 + w_4 u_4$, so $h = \frac{1}{1 + e^{-z}} = \sigma(z)$.

Using the chain rule:
\begin{align}
\frac{\partial h}{\partial \theta_j} &= \frac{\partial h}{\partial z} \cdot \frac{\partial z}{\partial \theta_j} \\
\frac{\partial h}{\partial w_j} &= \frac{\partial h}{\partial z} \cdot \frac{\partial z}{\partial w_j}
\end{align}

First, compute $\frac{\partial h}{\partial z}$:
\begin{align}
\frac{\partial h}{\partial z} = \frac{\partial}{\partial z}\left(\frac{1}{1 + e^{-z}}\right) = \frac{e^{-z}}{(1 + e^{-z})^2} = h(1-h)
\end{align}

Next, compute $\frac{\partial z}{\partial \theta_j}$:
\begin{align}
\frac{\partial z}{\partial \theta_1} &= w_1 x_1 + w_2 x_2 + w_3 x_4 + w_4 x_5 \\
\frac{\partial z}{\partial \theta_2} &= w_1 x_2 + w_2 x_3 + w_3 x_5 + w_4 x_6 \\
\frac{\partial z}{\partial \theta_3} &= w_1 x_4 + w_2 x_5 + w_3 x_7 + w_4 x_8 \\
\frac{\partial z}{\partial \theta_4} &= w_1 x_5 + w_2 x_6 + w_3 x_8 + w_4 x_9
\end{align}

And $\frac{\partial z}{\partial w_j}$:
\begin{align}
\frac{\partial z}{\partial w_1} = u_1, \quad \frac{\partial z}{\partial w_2} = u_2, \quad \frac{\partial z}{\partial w_3} = u_3, \quad \frac{\partial z}{\partial w_4} = u_4
\end{align}

Therefore:
\begin{align}
\frac{\partial h}{\partial \theta_1} &= h(1-h)(w_1 x_1 + w_2 x_2 + w_3 x_4 + w_4 x_5) \\
\frac{\partial h}{\partial \theta_2} &= h(1-h)(w_1 x_2 + w_2 x_3 + w_3 x_5 + w_4 x_6) \\
\frac{\partial h}{\partial \theta_3} &= h(1-h)(w_1 x_4 + w_2 x_5 + w_3 x_7 + w_4 x_8) \\
\frac{\partial h}{\partial \theta_4} &= h(1-h)(w_1 x_5 + w_2 x_6 + w_3 x_8 + w_4 x_9)
\end{align}

\begin{align}
\frac{\partial h}{\partial w_1} = h(1-h) u_1, \quad \frac{\partial h}{\partial w_2} = h(1-h) u_2, \quad \frac{\partial h}{\partial w_3} = h(1-h) u_3, \quad \frac{\partial h}{\partial w_4} = h(1-h) u_4
\end{align}

\section*{(b) Derive the negative log-likelihood function [3 marks]}

For binary classification with training dataset $\{(x_i, y_i)\}_{i=1}^N$ where $x_i \in \mathbb{R}^9$ and $y_i \in \{0,1\}$:

The likelihood for each data point is:
$$P(y_i | x_i) = h_i^{y_i} (1-h_i)^{1-y_i}$$
where $h_i = h(x_i, \theta, w)$.

The total likelihood is:
$$L(\theta, w) = \prod_{i=1}^N P(y_i | x_i) = \prod_{i=1}^N h_i^{y_i} (1-h_i)^{1-y_i}$$

The log-likelihood is:
$$\ell(\theta, w) = \sum_{i=1}^N [y_i \log h_i + (1-y_i) \log(1-h_i)]$$

Therefore, the negative log-likelihood function to minimize is:
$$\boxed{\text{NLL}(\theta, w) = -\sum_{i=1}^N [y_i \log h_i + (1-y_i) \log(1-h_i)]}$$

This is the binary cross-entropy loss function.

\section*{(c) SGD Algorithm with Mini-batch [8 marks]}

\begin{algorithm}
\caption{Stochastic Gradient Descent with Mini-batch}
\begin{algorithmic}[1]
\STATE \textbf{Initialize:} $\theta^{(0)}, w^{(0)}$ randomly, learning rate $\alpha > 0$, batch size $B$, max epochs $T$
\FOR{$t = 1$ to $T$}
    \STATE Randomly shuffle training data
    \STATE Divide data into mini-batches of size $B$
    \FOR{each mini-batch $\mathcal{B}$}
        \STATE \textbf{Forward Pass:}
        \FOR{each $(x_i, y_i) \in \mathcal{B}$}
            \STATE Compute $u_{1i}, u_{2i}, u_{3i}, u_{4i}$ using filter parameters $\theta$
            \STATE Compute $z_i = w_1 u_{1i} + w_2 u_{2i} + w_3 u_{3i} + w_4 u_{4i}$
            \STATE Compute $h_i = \frac{1}{1 + e^{-z_i}}$
        \ENDFOR
        \STATE \textbf{Compute Loss:}
        \STATE $L_{\text{batch}} = \frac{1}{B} \sum_{i \in \mathcal{B}} [-y_i \log h_i - (1-y_i) \log(1-h_i)]$
        \STATE \textbf{Backward Pass:}
        \FOR{$j = 1$ to $4$}
            \STATE $\frac{\partial L_{\text{batch}}}{\partial \theta_j} = \frac{1}{B} \sum_{i \in \mathcal{B}} (h_i - y_i) \cdot h_i(1-h_i) \cdot \frac{\partial z_i}{\partial \theta_j}$
            \STATE $\frac{\partial L_{\text{batch}}}{\partial w_j} = \frac{1}{B} \sum_{i \in \mathcal{B}} (h_i - y_i) \cdot h_i(1-h_i) \cdot u_{ji}$
        \ENDFOR
        \STATE \textbf{Parameter Update:}
        \FOR{$j = 1$ to $4$}
            \STATE $\theta_j \leftarrow \theta_j - \alpha \cdot \frac{\partial L_{\text{batch}}}{\partial \theta_j}$
            \STATE $w_j \leftarrow w_j - \alpha \cdot \frac{\partial L_{\text{batch}}}{\partial w_j}$
        \ENDFOR
    \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

\textbf{Key Points:}
\begin{itemize}
\item Mini-batch gradient is an unbiased estimator of the true gradient
\item Batch size $B$ affects convergence: smaller $B$ adds more noise but may escape local minima
\item Learning rate $\alpha$ requires tuning: too large causes instability, too small causes slow convergence
\item Common practice: use learning rate scheduling (decay over time)
\item Validation set performance should be monitored to prevent overfitting
\end{itemize}

\end{document}
"""
    
    # ä¿å­˜LaTeXæ–‡ä»¶
    with open('/Users/guxiuchen/Desktop/æ•°æ®å¤„ç†/question3_solution.tex', 'w') as f:
        f.write(latex_content)
    
    print("âœ… LaTeXè§£ç­”å·²ä¿å­˜ä¸º question3_solution.tex")

def main():
    solve_cnn_question()
    part_a_gradients()
    part_b_likelihood()
    part_c_sgd_algorithm()
    create_latex_solution()
    
    print("\n" + "="*80)
    print("Question 3 è§£ç­”å®Œæˆï¼")
    print("="*80)
    
    print("\nğŸ“‹ ç­”æ¡ˆæ€»ç»“ï¼š")
    print("-" * 50)
    print("(a) æ¢¯åº¦è®¡ç®—ï¼š")
    print("    âˆ‚h/âˆ‚Î¸â±¼ = h(1-h) Ã— (å¯¹åº”çš„çº¿æ€§ç»„åˆ)")
    print("    âˆ‚h/âˆ‚wâ±¼ = h(1-h) Ã— uâ±¼")
    print()
    print("(b) è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š")
    print("    NLL(Î¸,w) = -âˆ‘[yáµ¢ log háµ¢ + (1-yáµ¢) log(1-háµ¢)]")
    print()
    print("(c) SGDç®—æ³•ï¼š")
    print("    1. åˆå§‹åŒ–å‚æ•°")
    print("    2. å¯¹æ¯ä¸ªmini-batchï¼šå‰å‘ä¼ æ’­â†’è®¡ç®—æŸå¤±â†’åå‘ä¼ æ’­â†’æ›´æ–°å‚æ•°")
    print("    3. é‡å¤ç›´åˆ°æ”¶æ•›")

if __name__ == "__main__":
    main()
